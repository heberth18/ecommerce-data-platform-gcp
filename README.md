# ğŸš€ E-commerce Data Engineering Pipeline

## ğŸ“Š Contexto de Negocio

**Empresa:** Startup e-commerce B2C en Chile  
**Problema:** Necesidad de mÃ©tricas confiables, reproducibles y auditables de ventas y clientes  
**SoluciÃ³n:** Pipeline de datos end-to-end orquestado, contenerizado y escalable

---

## ğŸ¯ Objetivo

Generar KPIs mensuales de ventas y clientes listos para consumo analÃ­tico (BI y toma de decisiones).

---

## ğŸ—ï¸ Arquitectura

```
FakeAPI â†’ Airflow â†’ GCS (Bronze) â†’ BigQuery (Bronze) â†’ dbt â†’ BigQuery (Gold) â†’ BI
```

### Capas de Datos

1. **Bronze (Raw):** Datos crudos desde la API, almacenados en GCS y BigQuery sin transformaciones
2. **Silver (Staging):** Limpieza bÃ¡sica, tipado correcto, deduplicaciÃ³n
3. **Gold (Analytics):** Modelos dimensionales (fact/dim) y KPIs agregados

---

## ğŸ› ï¸ Stack TecnolÃ³gico

| Componente | TecnologÃ­a | JustificaciÃ³n |
|------------|------------|---------------|
| **OrquestaciÃ³n** | Apache Airflow | EstÃ¡ndar industria para workflows complejos, monitoreo visual, retry logic |
| **Almacenamiento** | Google Cloud Storage | Data Lake escalable, bajo costo, integraciÃ³n nativa con BigQuery |
| **Data Warehouse** | Google BigQuery | SeparaciÃ³n compute/storage, SQL estÃ¡ndar, optimizado para analytics |
| **Transformaciones** | dbt | Versionamiento de lÃ³gica de negocio, tests, documentaciÃ³n como cÃ³digo |
| **Contenedores** | Docker Compose | Reproducibilidad, portabilidad, aislamiento de dependencias |
| **Fuente de Datos** | FakeAPI | Simula sistema transaccional de e-commerce |

---

## ğŸ“ Estructura del Proyecto

```
project_ecommerce/
â”œâ”€â”€ airflow/                    # OrquestaciÃ³n
â”‚   â”œâ”€â”€ dags/                   # DAGs de Airflow
â”‚   â”œâ”€â”€ plugins/                # Operadores custom
â”‚   â”œâ”€â”€ scripts/                # Scripts de extracciÃ³n/carga
â”‚   â””â”€â”€ config/                 # Configuraciones
â”œâ”€â”€ dbt/                        # Transformaciones
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/            # Limpieza y validaciÃ³n
â”‚   â”‚   â”œâ”€â”€ marts/
â”‚   â”‚   â”‚   â”œâ”€â”€ core/           # Facts y Dimensions
â”‚   â”‚   â”‚   â””â”€â”€ kpis/           # KPIs agregados
â”‚   â”œâ”€â”€ tests/                  # Tests de calidad
â”‚   â””â”€â”€ macros/                 # Funciones reutilizables
â”œâ”€â”€ docker/                     # Configuraciones Docker
â”œâ”€â”€ docs/                       # DocumentaciÃ³n tÃ©cnica
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”„ Pipeline de Datos

### DAG Principal: `ecommerce_pipeline`

**Frecuencia:** Diaria (puede ajustarse a mensual para KPIs)

**Tareas:**

1. `extract_from_fakeapi`: Extrae datos de FakeAPI â†’ GCS (formato JSON)
2. `load_to_bigquery_bronze`: Carga desde GCS â†’ BigQuery (tablas bronze)
3. `dbt_run_staging`: Limpieza y validaciÃ³n (modelos staging)
4. `dbt_run_marts`: Genera facts, dimensions y KPIs
5. `dbt_test`: Valida calidad de datos

---

## ğŸ—‚ï¸ Modelos de Datos

### Bronze (Raw)
- `bronze_customers`
- `bronze_products`
- `bronze_orders`
- `bronze_order_items`
- `bronze_payments`

### Staging
- `stg_customers`
- `stg_products`
- `stg_orders`
- `stg_order_items`
- `stg_payments`

### Marts
- **Dimensions:**
  - `dim_customers`
  - `dim_products`
  - `dim_date`
- **Facts:**
  - `fact_orders`
- **KPIs:**
  - `kpi_monthly_sales`
  - `kpi_customer_metrics`

---

## ğŸš€ CÃ³mo Ejecutar

### Prerrequisitos

1. Docker y Docker Compose instalados
2. Cuenta de Google Cloud Platform
3. Proyecto GCP creado
4. Service Account con permisos:
   - BigQuery Admin
   - Storage Admin

### Setup Inicial

```bash
# 1. Clonar repositorio
git clone <repo-url>
cd project_ecommerce

# 2. Configurar variables de entorno
cp .env.example .env
# Editar .env con tus credenciales GCP

# 3. Colocar service account key
# Guardar archivo JSON en: ./secrets/gcp-service-account.json

# 4. Levantar servicios
docker-compose up -d

# 5. Acceder a Airflow
# http://localhost:8080
# User: airflow
# Password: airflow
```

---

## ğŸ“Š KPIs Implementados (Fase 1)

1. **Ventas Mensuales Totales:** Ingresos agregados por mes
2. **Cantidad de Ã“rdenes:** Total de Ã³rdenes procesadas
3. **Ticket Promedio:** Valor promedio por orden
4. **Clientes Activos:** Clientes Ãºnicos con compras en el perÃ­odo
5. **Productos MÃ¡s Vendidos:** Top 10 productos por cantidad

---

## ğŸ§ª Validaciones y Tests

- **Unicidad:** Primary keys Ãºnicos en facts y dimensions
- **Completitud:** Campos obligatorios no nulos
- **Relaciones:** Foreign keys vÃ¡lidas
- **Rango:** Montos positivos, fechas vÃ¡lidas

---

## ğŸ“ Convenciones de Commits

- `feat:` Nueva funcionalidad
- `fix:` CorrecciÃ³n de bugs
- `test:` Agregar tests
- `docs:` DocumentaciÃ³n
- `refactor:` Mejoras de cÃ³digo sin cambiar funcionalidad
- `perf:` Optimizaciones de rendimiento

---

## ğŸ“§ Contacto

Heberth Caripa - [LinkedIn](www.linkedin.com/in/heberth-caripa) - [GitHub](https://github.com/heberth18)

---

## ğŸ“„ Licencia

MIT

---
---

# ğŸš€ E-commerce Data Engineering Pipeline

**[English Version]**

## ğŸ“Š Business Context

**Company:** B2C e-commerce Startup in Chile  
**Problem:** Need for reliable, reproducible, and auditable sales and customer metrics  
**Solution:** End-to-end orchestrated, containerized, and scalable data pipeline

---

## ğŸ¯ Objective

Generate monthly sales and customer KPIs ready for analytical consumption (BI and decision-making).

---

## ğŸ—ï¸ Architecture

```
FakeAPI â†’ Airflow â†’ GCS (Bronze) â†’ BigQuery (Bronze) â†’ dbt â†’ BigQuery (Gold) â†’ BI
```

### Data Layers

1. **Bronze (Raw):** Raw data from the API, stored in GCS and BigQuery without transformations
2. **Silver (Staging):** Basic cleaning, correct typing, deduplication
3. **Gold (Analytics):** Dimensional models (fact/dim) and aggregated KPIs

---

## ğŸ› ï¸ Technology Stack

| Component | Technology | Justification |
|-----------|------------|---------------|
| **Orchestration** | Apache Airflow | Industry standard for complex workflows, visual monitoring, retry logic |
| **Storage** | Google Cloud Storage | Scalable Data Lake, low cost, native BigQuery integration |
| **Data Warehouse** | Google BigQuery | Compute/storage separation, standard SQL, optimized for analytics |
| **Transformations** | dbt | Business logic versioning, tests, documentation as code |
| **Containers** | Docker Compose | Reproducibility, portability, dependency isolation |
| **Data Source** | FakeAPI | Simulates e-commerce transactional system |

---

## ğŸ“ Project Structure

```
project_ecommerce/
â”œâ”€â”€ airflow/                    # Orchestration
â”‚   â”œâ”€â”€ dags/                   # Airflow DAGs
â”‚   â”œâ”€â”€ plugins/                # Custom operators
â”‚   â”œâ”€â”€ scripts/                # Extraction/loading scripts
â”‚   â””â”€â”€ config/                 # Configurations
â”œâ”€â”€ dbt/                        # Transformations
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/            # Cleaning and validation
â”‚   â”‚   â”œâ”€â”€ marts/
â”‚   â”‚   â”‚   â”œâ”€â”€ core/           # Facts and Dimensions
â”‚   â”‚   â”‚   â””â”€â”€ kpis/           # Aggregated KPIs
â”‚   â”œâ”€â”€ tests/                  # Quality tests
â”‚   â””â”€â”€ macros/                 # Reusable functions
â”œâ”€â”€ docker/                     # Docker configurations
â”œâ”€â”€ docs/                       # Technical documentation
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”„ Data Pipeline

### Main DAG: `ecommerce_pipeline`

**Frequency:** Daily (can be adjusted to monthly for KPIs)

**Tasks:**

1. `extract_from_fakeapi`: Extract data from FakeAPI â†’ GCS (JSON format)
2. `load_to_bigquery_bronze`: Load from GCS â†’ BigQuery (bronze tables)
3. `dbt_run_staging`: Cleaning and validation (staging models)
4. `dbt_run_marts`: Generate facts, dimensions and KPIs
5. `dbt_test`: Validate data quality

---

## ğŸ—‚ï¸ Data Models

### Bronze (Raw)
- `bronze_customers`
- `bronze_products`
- `bronze_orders`
- `bronze_order_items`
- `bronze_payments`

### Staging
- `stg_customers`
- `stg_products`
- `stg_orders`
- `stg_order_items`
- `stg_payments`

### Marts
- **Dimensions:**
  - `dim_customers`
  - `dim_products`
  - `dim_date`
- **Facts:**
  - `fact_orders`
- **KPIs:**
  - `kpi_monthly_sales`
  - `kpi_customer_metrics`

---

## ğŸš€ How to Run

### Prerequisites

1. Docker and Docker Compose installed
2. Google Cloud Platform account
3. GCP project created
4. Service Account with permissions:
   - BigQuery Admin
   - Storage Admin

### Initial Setup

```bash
# 1. Clone repository
git clone <repo-url>
cd project_ecommerce

# 2. Configure environment variables
cp env.example .env
# Edit .env with your GCP credentials

# 3. Place service account key
# Save JSON file to: ./secrets/gcp-service-account.json

# 4. Start services
docker-compose up -d

# 5. Access Airflow
# http://localhost:8080
# User: airflow
# Password: airflow
```

---

## ğŸ“Š Implemented KPIs (Phase 1)

1. **Total Monthly Sales:** Revenue aggregated by month
2. **Order Quantity:** Total processed orders
3. **Average Ticket:** Average value per order
4. **Active Customers:** Unique customers with purchases in the period
5. **Best-Selling Products:** Top 10 products by quantity

---

## ğŸ§ª Validations and Tests

- **Uniqueness:** Unique primary keys in facts and dimensions
- **Completeness:** Non-null mandatory fields
- **Relationships:** Valid foreign keys
- **Range:** Positive amounts, valid dates

---

## ğŸ“ Commit Conventions

- `feat:` New functionality
- `fix:` Bug fixes
- `test:` Add tests
- `docs:` Documentation
- `refactor:` Code improvements without changing functionality
- `perf:` Performance optimizations

---

## ğŸ“§ Contact

Heberth Caripa - [LinkedIn](www.linkedin.com/in/heberth-caripa) - [GitHub](https://github.com/heberth18)

---

## ğŸ“„ License

MIT
